{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "6a86bbe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A 0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C2</td>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>237000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>B0</td>\n",
       "      <td>C11</td>\n",
       "      <td>D4</td>\n",
       "      <td>100</td>\n",
       "      <td>E4</td>\n",
       "      <td>F2</td>\n",
       "      <td>86193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C18</td>\n",
       "      <td>D0</td>\n",
       "      <td>0</td>\n",
       "      <td>E0</td>\n",
       "      <td>F2</td>\n",
       "      <td>169200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A2</td>\n",
       "      <td>B0</td>\n",
       "      <td>C11</td>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C67</td>\n",
       "      <td>D1</td>\n",
       "      <td>0</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>2623</td>\n",
       "      <td>A1</td>\n",
       "      <td>B0</td>\n",
       "      <td>C2</td>\n",
       "      <td>D1</td>\n",
       "      <td>0</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>2624</td>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C8</td>\n",
       "      <td>D1</td>\n",
       "      <td>0</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>129300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>2625</td>\n",
       "      <td>A0</td>\n",
       "      <td>BO</td>\n",
       "      <td>C7</td>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>275300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>2626</td>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C11</td>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>2627</td>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C2</td>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>191475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2628 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UID col_0   col_1 col_2 col_3  col_4 col_5 col_6       y\n",
       "0        0   A 0      B0    C2    D1    100    E1    F2  237000\n",
       "1        1    A1      B0   C11    D4    100    E4    F2   86193\n",
       "2        2    A0      B0   C18    D0      0    E0    F2  169200\n",
       "3        3    A2      B0   C11    D1    100    E1    F2   58000\n",
       "4        4    A0      B0   C67    D1      0    E1    F2  235000\n",
       "...    ...   ...     ...   ...   ...    ...   ...   ...     ...\n",
       "2623  2623    A1      B0    C2    D1      0    E1    F2  102100\n",
       "2624  2624    A0   B0       C8    D1      0    E1    F2  129300\n",
       "2625  2625    A0      BO    C7    D1    100    E1    F2  275300\n",
       "2626  2626    A0      B0   C11    D1    100    E1    F2  150000\n",
       "2627  2627    A0      B0    C2    D1    100    E1    F2  191475\n",
       "\n",
       "[2628 rows x 9 columns]"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "df = pd.read_csv(\"./Data/train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "b832e817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2628 entries, 0 to 2627\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   UID     2628 non-null   int64 \n",
      " 1   col_0   2489 non-null   object\n",
      " 2   col_1   2542 non-null   object\n",
      " 3   col_2   2628 non-null   object\n",
      " 4   col_3   2628 non-null   object\n",
      " 5   col_4   2628 non-null   int64 \n",
      " 6   col_5   2628 non-null   object\n",
      " 7   col_6   2516 non-null   object\n",
      " 8   y       2628 non-null   int64 \n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 184.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "f036073b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UID        0\n",
       "col_0    139\n",
       "col_1     86\n",
       "col_2      0\n",
       "col_3      0\n",
       "col_4      0\n",
       "col_5      0\n",
       "col_6    112\n",
       "y          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4868d39a",
   "metadata": {},
   "source": [
    "### So from the initial exploration we can see that col_0, col_1 and col_6 have null values and these columns have categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "6939fd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 2625 2626 2627]\n",
      "['A 0' 'A1' 'A0' 'A2' 'AO' nan ' A2   ' 'A0   ' 'A 1' ' A0   ' 'A3'\n",
      " 'A2   ' 'A 2' 'A1   ' 'A 3   ' ' A3   ' ' A1   ' 'A   3']\n",
      "['B0' 'B 0' ' B0   ' nan 'B0   ' 'B2' 'B3' 'BO' 'B1' 'B   3' 'B1   ']\n",
      "['C2' 'C11' 'C18' 'C67' 'C4' 'C52' 'C7' 'C36' 'C57' 'C9' 'C54' 'C41' 'C44'\n",
      " 'C15' 'C39' 'C40' 'C59' 'C27' 'C29' 'C3' 'C49' 'C33' 'C6' 'C53' 'C12'\n",
      " 'C1' 'C56' 'C30' 'C81' 'C26' 'C35' 'C22' 'C34' 'C58' 'C21' 'C47' 'C20'\n",
      " 'C28' 'C50' 'C89' 'C62' 'C92' 'C38' 'C19' 'C0' 'C70' 'C87' 'C69' 'C76'\n",
      " 'C48' 'C55' 'C85' 'C17' 'C25' 'C16' 'C63' 'C13' 'C46' 'C37' 'C90' 'C86'\n",
      " 'C31' 'C71' 'C83' 'C45' 'C61' 'C23' 'C88' 'C24' 'C51' 'C72' 'C65' 'C60'\n",
      " 'C64' 'C82' 'C68' 'C79' 'C5' 'C10' 'C77' 'C42' 'C43' 'C75' 'C8' 'C91'\n",
      " 'C80' 'C74' 'C14' 'C78' 'C66']\n",
      "['D1' 'D4' 'D0' 'D8' 'D2' 'D41' 'D12' 'D6' 'D53' 'D48' 'D66' 'D26' 'D42'\n",
      " 'D36' 'D68' 'D54' 'D9' 'D5' 'D55' 'D3' 'D75' 'D21' 'D24' 'D40' 'D16'\n",
      " 'D39' 'D58' 'D71' 'D32' 'D72' 'D15' 'D13' 'D31' 'D51' 'D76' 'D20' 'D22'\n",
      " 'D46' 'D10' 'D29' 'D19' 'D56' 'D62' 'D7' 'D23' 'D34' 'D38' 'D77' 'D64'\n",
      " 'D14' 'D60' 'D37' 'D44' 'D28' 'D45' 'D59' 'D47' 'D11' 'D30' 'D18' 'D27'\n",
      " 'D49' 'D33' 'D57' 'D35' 'D50' 'D65' 'D73']\n",
      "[100   0  50]\n",
      "['E1' 'E4' 'E0' 'E24' 'E2' 'E19' 'E11' 'E6' 'E52' 'E48' 'E63' 'E36' 'E23'\n",
      " 'E40' 'E32' 'E38' 'E18' 'E69' 'E8' 'E53' 'E3' 'E70' 'E5' 'E22' 'E45'\n",
      " 'E14' 'E35' 'E29' 'E67' 'E13' 'E28' 'E51' 'E61' 'E17' 'E20' 'E47' 'E12'\n",
      " 'E9' 'E49' 'E54' 'E60' 'E7' 'E21' 'E30' 'E34' 'E71' 'E64' 'E59' 'E33'\n",
      " 'E56' 'E43' 'E27' 'E25' 'E15' 'E58' 'E57' 'E46' 'E10' 'E16' 'E37' 'E26'\n",
      " 'E50' 'E42' 'E41' 'E44' 'E31' 'E62']\n",
      "['F2' 'F0' 'F1' nan 'F2   ' 'F 2' 'F0   ' 'F 0' ' F0   ' 'FO' ' F2   '\n",
      " ' F1   ' 'F 1' 'F1   ']\n",
      "[237000  86193 169200  58000 235000 170000 183600 100000 175000 136000\n",
      "  55685 120000 150000 152000  72000 140000 130000 248400 212200 127467\n",
      " 129000 201000  40000 270703 139000 180000  62649 189650  40570  12103\n",
      "   9727 105000 187000 128000  17684  20000 139500 145000 200100 104000\n",
      "  29751 102663 210000 168400 280700 191475  60000 260000 204500 236000\n",
      " 211500  78000 165000   7799  50432 153667 323300 110820  36773 210914\n",
      " 155000 195400 111775 148800  52533 225000 153000  75000   9272 159100\n",
      " 156400 135000 115000 190000  96100 172000 110600 285800 195652  21669\n",
      " 191200 109400 201450 228000 144000 240500 156600  59020 176000 147100\n",
      " 160000 276000  95000 275000  49253 105200 141525  70000 155850   8000\n",
      " 114500  40038  85066 200000 177000  51039 280000  85000 161311  48609\n",
      " 185000 247500 250000  15806 132100  89306  14307 186000  79833  55000\n",
      " 110000 153600 128058 168000  88256 124000 125000  15000 213580 193900\n",
      " 105500 122600 151902 275300 106000  60795 182750  90734  83000  34672\n",
      " 126000 157000 165220 122500 192500  46000 113000  86000 163800 220000\n",
      " 206000  90000 103691  80000 192600 142200  73880   6359  78990  18907\n",
      " 154000  24165  93918 188800  18000  81500 213660 169000 131300 240000\n",
      " 141600 122000 127000 104611 174000  50000 101570  66000 104500  65488\n",
      " 129300 141300  66970 134760 148750 209100 106500  45390 148700  61896\n",
      "  84053  61566 185900 179820  20984 175100 102500  92350  64090   6270\n",
      " 288000  81666 160288  72212 183500  85500 108000 167500  48289 105400\n",
      " 130240  33808  98506 119000  85847 179400 149600 121700 133832  38631\n",
      " 136100 182160 112000 230000 132320 137500 126500  22611 195000 416000\n",
      " 146000  76833  80481 205000   9289 167000 164000 205920 324000  73546\n",
      "  81000 102100 249500 202000 222200 208450  82000 102640 183310  40481\n",
      " 138750 128875  51753 109024 174500 207000 236900  33000 269000 143865\n",
      "  65666 128750 116000 183000 172309 130026 178800 216000 124234 151410\n",
      " 215000 423000  63040 195700 123405 252000  77262  98000 194500 112872\n",
      " 184000 172200  40777 231250 198800  52500 245100 219000  45760  37824\n",
      " 145885  50180 149040 225900 110037  42533 109280 200160  63312 173762\n",
      " 172800 153400  63000  87000 180180  68293  47280 144100 120250  67597\n",
      "  70186  13989  83171 284310 226700 115092 143200 133766 260500 143100\n",
      "  97218  93800 188000 195895  68400  75116  92000  69751 208000 202800\n",
      "  38400 198200 148000 196200  55800  12000 309400  69999  84000  66837\n",
      " 109000 350000  67723 136620  49268  99000 115500 310000  30000  59102\n",
      " 297300  17509 113750  42026 145900  60761 161800  26005  21844 258000\n",
      " 115440  79000 160080  38000 110500  62000  20171  66531 318300 147800\n",
      " 196000 234100 152500  45555 121600  65257 133300 106800 126080 170550\n",
      " 121500 121523  83500 106250  31520  75050 152900 300000 203300  87738\n",
      "  68318  73900  73000  56536  33609  31795 142800  74178  48000  61989\n",
      "  61800 100706 151800  28609 189750  82528  35093 220110  42197 265000\n",
      " 185700  99750 241000 101228 149850  38776 217000 317070  93700  65062\n",
      "  85700 216200 245000 253750 193000 300240 157750 117104  24823  12888\n",
      " 104890 199000  90700   6304 289800  25000  94564  72200  51508 161342\n",
      "  75344 115573  28369  75648  55410 134000  74540 115447 149076  77300\n",
      " 197000 171250 192400  97750 141288  43096  42000 112900  16228  64500\n",
      "  18238  72914  82365 116914 100500  62726  24000  57723  71907   5132\n",
      " 167580  74000  76309  53654   9466 212800  43809 172600 150075  44365\n",
      " 194000 203500 119300 179305  60757 189110 173000 250500  51081 154600\n",
      "  79197 159200  22800 162500 231500  60093  68428  51321 205600 110446\n",
      " 227000 122700 159832  46759  40663 259000 127221 177500  60938 119059\n",
      " 297500 223250  36259 376080 117000 213120  53416 236600 188700  91237\n",
      "  67141  46809 147000  92700 176100 215300  28399 128500 222000  46597\n",
      " 123000  88654 178600  24342  95746  65000  38154 115934 145828 208775\n",
      "  28368  47899 109371 239748 132300  39916  99100 158200 262500 222640\n",
      " 192000 102000  94300  41689 134236 184700 248700 125600  82280 325000\n",
      " 129400 132000  37558  94665 104697 128280  70500 182200 112300 229998\n",
      " 140800  54094  34320 136994 304000 243225  54000 286000  10000  53192\n",
      "  19073 229000 141290 213000 113900 164996 115222 239000 101943  90320\n",
      "  12767   7000 158677 380000  58331 106020  45618  17805 136260 293000\n",
      "  70139 195800  16904  25500 148500  89200 269600  94000 353200 212750\n",
      " 178750 198440 100800 253200 370000 166000 141846 272550  46178 243000\n",
      " 162000  61200  76814  45896 187500 140250 179975 127075  80036 107000\n",
      " 172386  15966  64385 209450 142000 150260 104650 143860  28016 243900\n",
      "  21461 246000  98200 257000  77684 175308  39925 146300  19609 102772\n",
      "  12877  37825  76958  60400 248100  80041 221300  88100 170500  30523\n",
      "  93000 140400   5679  12608   5409  96282 139600  54634 171000 166700\n",
      " 188100 193750 238000 206500  54685  69133  21013 340000 221000  75020\n",
      "  66022 134024 105700  51716 198000 314100 161000 116100 197430 249260\n",
      " 375000 385000 138900  96113 144200 153090  45391  67000 123700 156000\n",
      " 179775 192564  57872  18053 256000  66265 144854  56256  13493 227200\n",
      " 125404  58837 104300 115360  65013  99703  66100 138000  51962   5723\n",
      " 247300 224000 133200  71786 215050 145300 133000  25216 342300 154545\n",
      "  87980  95550 203100 114000  45050 159500  29453  21637 168100 203000\n",
      "  59888  71897  52008 181940 116450 137400 155499 130800 291500  61300\n",
      " 262000 133800 146200 105066 179000 206699  64980  17022  61467 219535\n",
      "   6072  23000 182500 289076  57000 107309 124500  19522 105236 138600\n",
      " 178500  82500 192037  72946 135446 123400 124740 214618 188500  82744\n",
      " 191765  99450  63900  42923 161500  91000   5707 255000 159000 109006\n",
      " 299500 121093 110925  52000 342810 202353 102839  33511 114047  56723\n",
      " 190200 165750 163625 167100 127599  51000 270000  20670  63192  56000\n",
      "  68000  63831 204100 120160 106260  89294 156868 172500  13400  22892\n",
      "  16414  94500 175950 158000 120600 107900 116150  24740 223800  28476\n",
      " 139860 105380  25532  86466  36000 214000]\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "83e3f5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A 0', 'A1', 'A0', 'A2', 'AO', nan, ' A2   ', 'A0   ', 'A 1',\n",
       "       ' A0   ', 'A3', 'A2   ', 'A 2', 'A1   ', 'A 3   ', ' A3   ',\n",
       "       ' A1   ', 'A   3'], dtype=object)"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.col_0.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "a42b92d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 2625 2626 2627]\n",
      "['A 0' 'A1' 'A0' 'A2' 'AO' nan 'A 1' 'A3' 'A 2' 'A 3' 'A   3']\n",
      "['B0' 'B 0' nan 'B2' 'B3' 'BO' 'B1' 'B   3']\n",
      "['C2' 'C11' 'C18' 'C67' 'C4' 'C52' 'C7' 'C36' 'C57' 'C9' 'C54' 'C41' 'C44'\n",
      " 'C15' 'C39' 'C40' 'C59' 'C27' 'C29' 'C3' 'C49' 'C33' 'C6' 'C53' 'C12'\n",
      " 'C1' 'C56' 'C30' 'C81' 'C26' 'C35' 'C22' 'C34' 'C58' 'C21' 'C47' 'C20'\n",
      " 'C28' 'C50' 'C89' 'C62' 'C92' 'C38' 'C19' 'C0' 'C70' 'C87' 'C69' 'C76'\n",
      " 'C48' 'C55' 'C85' 'C17' 'C25' 'C16' 'C63' 'C13' 'C46' 'C37' 'C90' 'C86'\n",
      " 'C31' 'C71' 'C83' 'C45' 'C61' 'C23' 'C88' 'C24' 'C51' 'C72' 'C65' 'C60'\n",
      " 'C64' 'C82' 'C68' 'C79' 'C5' 'C10' 'C77' 'C42' 'C43' 'C75' 'C8' 'C91'\n",
      " 'C80' 'C74' 'C14' 'C78' 'C66']\n",
      "['D1' 'D4' 'D0' 'D8' 'D2' 'D41' 'D12' 'D6' 'D53' 'D48' 'D66' 'D26' 'D42'\n",
      " 'D36' 'D68' 'D54' 'D9' 'D5' 'D55' 'D3' 'D75' 'D21' 'D24' 'D40' 'D16'\n",
      " 'D39' 'D58' 'D71' 'D32' 'D72' 'D15' 'D13' 'D31' 'D51' 'D76' 'D20' 'D22'\n",
      " 'D46' 'D10' 'D29' 'D19' 'D56' 'D62' 'D7' 'D23' 'D34' 'D38' 'D77' 'D64'\n",
      " 'D14' 'D60' 'D37' 'D44' 'D28' 'D45' 'D59' 'D47' 'D11' 'D30' 'D18' 'D27'\n",
      " 'D49' 'D33' 'D57' 'D35' 'D50' 'D65' 'D73']\n",
      "[100   0  50]\n",
      "['E1' 'E4' 'E0' 'E24' 'E2' 'E19' 'E11' 'E6' 'E52' 'E48' 'E63' 'E36' 'E23'\n",
      " 'E40' 'E32' 'E38' 'E18' 'E69' 'E8' 'E53' 'E3' 'E70' 'E5' 'E22' 'E45'\n",
      " 'E14' 'E35' 'E29' 'E67' 'E13' 'E28' 'E51' 'E61' 'E17' 'E20' 'E47' 'E12'\n",
      " 'E9' 'E49' 'E54' 'E60' 'E7' 'E21' 'E30' 'E34' 'E71' 'E64' 'E59' 'E33'\n",
      " 'E56' 'E43' 'E27' 'E25' 'E15' 'E58' 'E57' 'E46' 'E10' 'E16' 'E37' 'E26'\n",
      " 'E50' 'E42' 'E41' 'E44' 'E31' 'E62']\n",
      "['F2' 'F0' 'F1' nan 'F 2' 'F 0' 'FO' 'F 1']\n",
      "[237000  86193 169200  58000 235000 170000 183600 100000 175000 136000\n",
      "  55685 120000 150000 152000  72000 140000 130000 248400 212200 127467\n",
      " 129000 201000  40000 270703 139000 180000  62649 189650  40570  12103\n",
      "   9727 105000 187000 128000  17684  20000 139500 145000 200100 104000\n",
      "  29751 102663 210000 168400 280700 191475  60000 260000 204500 236000\n",
      " 211500  78000 165000   7799  50432 153667 323300 110820  36773 210914\n",
      " 155000 195400 111775 148800  52533 225000 153000  75000   9272 159100\n",
      " 156400 135000 115000 190000  96100 172000 110600 285800 195652  21669\n",
      " 191200 109400 201450 228000 144000 240500 156600  59020 176000 147100\n",
      " 160000 276000  95000 275000  49253 105200 141525  70000 155850   8000\n",
      " 114500  40038  85066 200000 177000  51039 280000  85000 161311  48609\n",
      " 185000 247500 250000  15806 132100  89306  14307 186000  79833  55000\n",
      " 110000 153600 128058 168000  88256 124000 125000  15000 213580 193900\n",
      " 105500 122600 151902 275300 106000  60795 182750  90734  83000  34672\n",
      " 126000 157000 165220 122500 192500  46000 113000  86000 163800 220000\n",
      " 206000  90000 103691  80000 192600 142200  73880   6359  78990  18907\n",
      " 154000  24165  93918 188800  18000  81500 213660 169000 131300 240000\n",
      " 141600 122000 127000 104611 174000  50000 101570  66000 104500  65488\n",
      " 129300 141300  66970 134760 148750 209100 106500  45390 148700  61896\n",
      "  84053  61566 185900 179820  20984 175100 102500  92350  64090   6270\n",
      " 288000  81666 160288  72212 183500  85500 108000 167500  48289 105400\n",
      " 130240  33808  98506 119000  85847 179400 149600 121700 133832  38631\n",
      " 136100 182160 112000 230000 132320 137500 126500  22611 195000 416000\n",
      " 146000  76833  80481 205000   9289 167000 164000 205920 324000  73546\n",
      "  81000 102100 249500 202000 222200 208450  82000 102640 183310  40481\n",
      " 138750 128875  51753 109024 174500 207000 236900  33000 269000 143865\n",
      "  65666 128750 116000 183000 172309 130026 178800 216000 124234 151410\n",
      " 215000 423000  63040 195700 123405 252000  77262  98000 194500 112872\n",
      " 184000 172200  40777 231250 198800  52500 245100 219000  45760  37824\n",
      " 145885  50180 149040 225900 110037  42533 109280 200160  63312 173762\n",
      " 172800 153400  63000  87000 180180  68293  47280 144100 120250  67597\n",
      "  70186  13989  83171 284310 226700 115092 143200 133766 260500 143100\n",
      "  97218  93800 188000 195895  68400  75116  92000  69751 208000 202800\n",
      "  38400 198200 148000 196200  55800  12000 309400  69999  84000  66837\n",
      " 109000 350000  67723 136620  49268  99000 115500 310000  30000  59102\n",
      " 297300  17509 113750  42026 145900  60761 161800  26005  21844 258000\n",
      " 115440  79000 160080  38000 110500  62000  20171  66531 318300 147800\n",
      " 196000 234100 152500  45555 121600  65257 133300 106800 126080 170550\n",
      " 121500 121523  83500 106250  31520  75050 152900 300000 203300  87738\n",
      "  68318  73900  73000  56536  33609  31795 142800  74178  48000  61989\n",
      "  61800 100706 151800  28609 189750  82528  35093 220110  42197 265000\n",
      " 185700  99750 241000 101228 149850  38776 217000 317070  93700  65062\n",
      "  85700 216200 245000 253750 193000 300240 157750 117104  24823  12888\n",
      " 104890 199000  90700   6304 289800  25000  94564  72200  51508 161342\n",
      "  75344 115573  28369  75648  55410 134000  74540 115447 149076  77300\n",
      " 197000 171250 192400  97750 141288  43096  42000 112900  16228  64500\n",
      "  18238  72914  82365 116914 100500  62726  24000  57723  71907   5132\n",
      " 167580  74000  76309  53654   9466 212800  43809 172600 150075  44365\n",
      " 194000 203500 119300 179305  60757 189110 173000 250500  51081 154600\n",
      "  79197 159200  22800 162500 231500  60093  68428  51321 205600 110446\n",
      " 227000 122700 159832  46759  40663 259000 127221 177500  60938 119059\n",
      " 297500 223250  36259 376080 117000 213120  53416 236600 188700  91237\n",
      "  67141  46809 147000  92700 176100 215300  28399 128500 222000  46597\n",
      " 123000  88654 178600  24342  95746  65000  38154 115934 145828 208775\n",
      "  28368  47899 109371 239748 132300  39916  99100 158200 262500 222640\n",
      " 192000 102000  94300  41689 134236 184700 248700 125600  82280 325000\n",
      " 129400 132000  37558  94665 104697 128280  70500 182200 112300 229998\n",
      " 140800  54094  34320 136994 304000 243225  54000 286000  10000  53192\n",
      "  19073 229000 141290 213000 113900 164996 115222 239000 101943  90320\n",
      "  12767   7000 158677 380000  58331 106020  45618  17805 136260 293000\n",
      "  70139 195800  16904  25500 148500  89200 269600  94000 353200 212750\n",
      " 178750 198440 100800 253200 370000 166000 141846 272550  46178 243000\n",
      " 162000  61200  76814  45896 187500 140250 179975 127075  80036 107000\n",
      " 172386  15966  64385 209450 142000 150260 104650 143860  28016 243900\n",
      "  21461 246000  98200 257000  77684 175308  39925 146300  19609 102772\n",
      "  12877  37825  76958  60400 248100  80041 221300  88100 170500  30523\n",
      "  93000 140400   5679  12608   5409  96282 139600  54634 171000 166700\n",
      " 188100 193750 238000 206500  54685  69133  21013 340000 221000  75020\n",
      "  66022 134024 105700  51716 198000 314100 161000 116100 197430 249260\n",
      " 375000 385000 138900  96113 144200 153090  45391  67000 123700 156000\n",
      " 179775 192564  57872  18053 256000  66265 144854  56256  13493 227200\n",
      " 125404  58837 104300 115360  65013  99703  66100 138000  51962   5723\n",
      " 247300 224000 133200  71786 215050 145300 133000  25216 342300 154545\n",
      "  87980  95550 203100 114000  45050 159500  29453  21637 168100 203000\n",
      "  59888  71897  52008 181940 116450 137400 155499 130800 291500  61300\n",
      " 262000 133800 146200 105066 179000 206699  64980  17022  61467 219535\n",
      "   6072  23000 182500 289076  57000 107309 124500  19522 105236 138600\n",
      " 178500  82500 192037  72946 135446 123400 124740 214618 188500  82744\n",
      " 191765  99450  63900  42923 161500  91000   5707 255000 159000 109006\n",
      " 299500 121093 110925  52000 342810 202353 102839  33511 114047  56723\n",
      " 190200 165750 163625 167100 127599  51000 270000  20670  63192  56000\n",
      "  68000  63831 204100 120160 106260  89294 156868 172500  13400  22892\n",
      "  16414  94500 175950 158000 120600 107900 116150  24740 223800  28476\n",
      " 139860 105380  25532  86466  36000 214000]\n"
     ]
    }
   ],
   "source": [
    "cols = ['col_0', 'col_1', 'col_6']\n",
    "for col in cols:\n",
    "    df[col] = df[col].str.strip()\n",
    "    \n",
    "for col in df.columns:\n",
    "    print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "8455adfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0 : ['A 0' 'A1' 'A0' 'A2' 'AO' nan 'A 1' 'A3' 'A 2' 'A 3' 'A   3']\n",
      "col_1 : ['B0' 'B 0' nan 'B2' 'B3' 'BO' 'B1' 'B   3']\n",
      "col_6 : ['F2' 'F0' 'F1' nan 'F 2' 'F 0' 'FO' 'F 1']\n"
     ]
    }
   ],
   "source": [
    "for col in cols:\n",
    "    print(f\"{col} : {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "1d8fc914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col_0'] = df['col_0'].replace({'A 0': 'A0', 'AO': 'A0', 'A 1':'A1', 'A 2':'A2', 'A 3':'A3', 'A   3':'A3'})\n",
    "df['col_1'] = df['col_1'].replace({'B 0': 'B0', 'BO': 'B0', 'B   3': 'B3'})\n",
    "df['col_6'] = df['col_6'].replace({'F 2': 'F2', 'F 0': 'F0', 'FO': 'F0', 'F 1':'F1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "b24f53b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UID : [   0    1    2 ... 2625 2626 2627]\n",
      "col_0 : ['A0' 'A1' 'A2' nan 'A3']\n",
      "col_1 : ['B0' nan 'B2' 'B3' 'B1']\n",
      "col_2 : ['C2' 'C11' 'C18' 'C67' 'C4' 'C52' 'C7' 'C36' 'C57' 'C9' 'C54' 'C41' 'C44'\n",
      " 'C15' 'C39' 'C40' 'C59' 'C27' 'C29' 'C3' 'C49' 'C33' 'C6' 'C53' 'C12'\n",
      " 'C1' 'C56' 'C30' 'C81' 'C26' 'C35' 'C22' 'C34' 'C58' 'C21' 'C47' 'C20'\n",
      " 'C28' 'C50' 'C89' 'C62' 'C92' 'C38' 'C19' 'C0' 'C70' 'C87' 'C69' 'C76'\n",
      " 'C48' 'C55' 'C85' 'C17' 'C25' 'C16' 'C63' 'C13' 'C46' 'C37' 'C90' 'C86'\n",
      " 'C31' 'C71' 'C83' 'C45' 'C61' 'C23' 'C88' 'C24' 'C51' 'C72' 'C65' 'C60'\n",
      " 'C64' 'C82' 'C68' 'C79' 'C5' 'C10' 'C77' 'C42' 'C43' 'C75' 'C8' 'C91'\n",
      " 'C80' 'C74' 'C14' 'C78' 'C66']\n",
      "col_3 : ['D1' 'D4' 'D0' 'D8' 'D2' 'D41' 'D12' 'D6' 'D53' 'D48' 'D66' 'D26' 'D42'\n",
      " 'D36' 'D68' 'D54' 'D9' 'D5' 'D55' 'D3' 'D75' 'D21' 'D24' 'D40' 'D16'\n",
      " 'D39' 'D58' 'D71' 'D32' 'D72' 'D15' 'D13' 'D31' 'D51' 'D76' 'D20' 'D22'\n",
      " 'D46' 'D10' 'D29' 'D19' 'D56' 'D62' 'D7' 'D23' 'D34' 'D38' 'D77' 'D64'\n",
      " 'D14' 'D60' 'D37' 'D44' 'D28' 'D45' 'D59' 'D47' 'D11' 'D30' 'D18' 'D27'\n",
      " 'D49' 'D33' 'D57' 'D35' 'D50' 'D65' 'D73']\n",
      "col_4 : [100   0  50]\n",
      "col_5 : ['E1' 'E4' 'E0' 'E24' 'E2' 'E19' 'E11' 'E6' 'E52' 'E48' 'E63' 'E36' 'E23'\n",
      " 'E40' 'E32' 'E38' 'E18' 'E69' 'E8' 'E53' 'E3' 'E70' 'E5' 'E22' 'E45'\n",
      " 'E14' 'E35' 'E29' 'E67' 'E13' 'E28' 'E51' 'E61' 'E17' 'E20' 'E47' 'E12'\n",
      " 'E9' 'E49' 'E54' 'E60' 'E7' 'E21' 'E30' 'E34' 'E71' 'E64' 'E59' 'E33'\n",
      " 'E56' 'E43' 'E27' 'E25' 'E15' 'E58' 'E57' 'E46' 'E10' 'E16' 'E37' 'E26'\n",
      " 'E50' 'E42' 'E41' 'E44' 'E31' 'E62']\n",
      "col_6 : ['F2' 'F0' 'F1' nan]\n",
      "y : [237000  86193 169200  58000 235000 170000 183600 100000 175000 136000\n",
      "  55685 120000 150000 152000  72000 140000 130000 248400 212200 127467\n",
      " 129000 201000  40000 270703 139000 180000  62649 189650  40570  12103\n",
      "   9727 105000 187000 128000  17684  20000 139500 145000 200100 104000\n",
      "  29751 102663 210000 168400 280700 191475  60000 260000 204500 236000\n",
      " 211500  78000 165000   7799  50432 153667 323300 110820  36773 210914\n",
      " 155000 195400 111775 148800  52533 225000 153000  75000   9272 159100\n",
      " 156400 135000 115000 190000  96100 172000 110600 285800 195652  21669\n",
      " 191200 109400 201450 228000 144000 240500 156600  59020 176000 147100\n",
      " 160000 276000  95000 275000  49253 105200 141525  70000 155850   8000\n",
      " 114500  40038  85066 200000 177000  51039 280000  85000 161311  48609\n",
      " 185000 247500 250000  15806 132100  89306  14307 186000  79833  55000\n",
      " 110000 153600 128058 168000  88256 124000 125000  15000 213580 193900\n",
      " 105500 122600 151902 275300 106000  60795 182750  90734  83000  34672\n",
      " 126000 157000 165220 122500 192500  46000 113000  86000 163800 220000\n",
      " 206000  90000 103691  80000 192600 142200  73880   6359  78990  18907\n",
      " 154000  24165  93918 188800  18000  81500 213660 169000 131300 240000\n",
      " 141600 122000 127000 104611 174000  50000 101570  66000 104500  65488\n",
      " 129300 141300  66970 134760 148750 209100 106500  45390 148700  61896\n",
      "  84053  61566 185900 179820  20984 175100 102500  92350  64090   6270\n",
      " 288000  81666 160288  72212 183500  85500 108000 167500  48289 105400\n",
      " 130240  33808  98506 119000  85847 179400 149600 121700 133832  38631\n",
      " 136100 182160 112000 230000 132320 137500 126500  22611 195000 416000\n",
      " 146000  76833  80481 205000   9289 167000 164000 205920 324000  73546\n",
      "  81000 102100 249500 202000 222200 208450  82000 102640 183310  40481\n",
      " 138750 128875  51753 109024 174500 207000 236900  33000 269000 143865\n",
      "  65666 128750 116000 183000 172309 130026 178800 216000 124234 151410\n",
      " 215000 423000  63040 195700 123405 252000  77262  98000 194500 112872\n",
      " 184000 172200  40777 231250 198800  52500 245100 219000  45760  37824\n",
      " 145885  50180 149040 225900 110037  42533 109280 200160  63312 173762\n",
      " 172800 153400  63000  87000 180180  68293  47280 144100 120250  67597\n",
      "  70186  13989  83171 284310 226700 115092 143200 133766 260500 143100\n",
      "  97218  93800 188000 195895  68400  75116  92000  69751 208000 202800\n",
      "  38400 198200 148000 196200  55800  12000 309400  69999  84000  66837\n",
      " 109000 350000  67723 136620  49268  99000 115500 310000  30000  59102\n",
      " 297300  17509 113750  42026 145900  60761 161800  26005  21844 258000\n",
      " 115440  79000 160080  38000 110500  62000  20171  66531 318300 147800\n",
      " 196000 234100 152500  45555 121600  65257 133300 106800 126080 170550\n",
      " 121500 121523  83500 106250  31520  75050 152900 300000 203300  87738\n",
      "  68318  73900  73000  56536  33609  31795 142800  74178  48000  61989\n",
      "  61800 100706 151800  28609 189750  82528  35093 220110  42197 265000\n",
      " 185700  99750 241000 101228 149850  38776 217000 317070  93700  65062\n",
      "  85700 216200 245000 253750 193000 300240 157750 117104  24823  12888\n",
      " 104890 199000  90700   6304 289800  25000  94564  72200  51508 161342\n",
      "  75344 115573  28369  75648  55410 134000  74540 115447 149076  77300\n",
      " 197000 171250 192400  97750 141288  43096  42000 112900  16228  64500\n",
      "  18238  72914  82365 116914 100500  62726  24000  57723  71907   5132\n",
      " 167580  74000  76309  53654   9466 212800  43809 172600 150075  44365\n",
      " 194000 203500 119300 179305  60757 189110 173000 250500  51081 154600\n",
      "  79197 159200  22800 162500 231500  60093  68428  51321 205600 110446\n",
      " 227000 122700 159832  46759  40663 259000 127221 177500  60938 119059\n",
      " 297500 223250  36259 376080 117000 213120  53416 236600 188700  91237\n",
      "  67141  46809 147000  92700 176100 215300  28399 128500 222000  46597\n",
      " 123000  88654 178600  24342  95746  65000  38154 115934 145828 208775\n",
      "  28368  47899 109371 239748 132300  39916  99100 158200 262500 222640\n",
      " 192000 102000  94300  41689 134236 184700 248700 125600  82280 325000\n",
      " 129400 132000  37558  94665 104697 128280  70500 182200 112300 229998\n",
      " 140800  54094  34320 136994 304000 243225  54000 286000  10000  53192\n",
      "  19073 229000 141290 213000 113900 164996 115222 239000 101943  90320\n",
      "  12767   7000 158677 380000  58331 106020  45618  17805 136260 293000\n",
      "  70139 195800  16904  25500 148500  89200 269600  94000 353200 212750\n",
      " 178750 198440 100800 253200 370000 166000 141846 272550  46178 243000\n",
      " 162000  61200  76814  45896 187500 140250 179975 127075  80036 107000\n",
      " 172386  15966  64385 209450 142000 150260 104650 143860  28016 243900\n",
      "  21461 246000  98200 257000  77684 175308  39925 146300  19609 102772\n",
      "  12877  37825  76958  60400 248100  80041 221300  88100 170500  30523\n",
      "  93000 140400   5679  12608   5409  96282 139600  54634 171000 166700\n",
      " 188100 193750 238000 206500  54685  69133  21013 340000 221000  75020\n",
      "  66022 134024 105700  51716 198000 314100 161000 116100 197430 249260\n",
      " 375000 385000 138900  96113 144200 153090  45391  67000 123700 156000\n",
      " 179775 192564  57872  18053 256000  66265 144854  56256  13493 227200\n",
      " 125404  58837 104300 115360  65013  99703  66100 138000  51962   5723\n",
      " 247300 224000 133200  71786 215050 145300 133000  25216 342300 154545\n",
      "  87980  95550 203100 114000  45050 159500  29453  21637 168100 203000\n",
      "  59888  71897  52008 181940 116450 137400 155499 130800 291500  61300\n",
      " 262000 133800 146200 105066 179000 206699  64980  17022  61467 219535\n",
      "   6072  23000 182500 289076  57000 107309 124500  19522 105236 138600\n",
      " 178500  82500 192037  72946 135446 123400 124740 214618 188500  82744\n",
      " 191765  99450  63900  42923 161500  91000   5707 255000 159000 109006\n",
      " 299500 121093 110925  52000 342810 202353 102839  33511 114047  56723\n",
      " 190200 165750 163625 167100 127599  51000 270000  20670  63192  56000\n",
      "  68000  63831 204100 120160 106260  89294 156868 172500  13400  22892\n",
      "  16414  94500 175950 158000 120600 107900 116150  24740 223800  28476\n",
      " 139860 105380  25532  86466  36000 214000]\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"{col} : {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "ec147aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C2</td>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>237000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>B0</td>\n",
       "      <td>C11</td>\n",
       "      <td>D4</td>\n",
       "      <td>100</td>\n",
       "      <td>E4</td>\n",
       "      <td>F2</td>\n",
       "      <td>86193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C18</td>\n",
       "      <td>D0</td>\n",
       "      <td>0</td>\n",
       "      <td>E0</td>\n",
       "      <td>F2</td>\n",
       "      <td>169200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A2</td>\n",
       "      <td>B0</td>\n",
       "      <td>C11</td>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C67</td>\n",
       "      <td>D1</td>\n",
       "      <td>0</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>2623</td>\n",
       "      <td>A1</td>\n",
       "      <td>B0</td>\n",
       "      <td>C2</td>\n",
       "      <td>D1</td>\n",
       "      <td>0</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>2624</td>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C8</td>\n",
       "      <td>D1</td>\n",
       "      <td>0</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>129300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>2625</td>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C7</td>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>275300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>2626</td>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C11</td>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>2627</td>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C2</td>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>191475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2628 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UID col_0 col_1 col_2 col_3  col_4 col_5 col_6       y\n",
       "0        0    A0    B0    C2    D1    100    E1    F2  237000\n",
       "1        1    A1    B0   C11    D4    100    E4    F2   86193\n",
       "2        2    A0    B0   C18    D0      0    E0    F2  169200\n",
       "3        3    A2    B0   C11    D1    100    E1    F2   58000\n",
       "4        4    A0    B0   C67    D1      0    E1    F2  235000\n",
       "...    ...   ...   ...   ...   ...    ...   ...   ...     ...\n",
       "2623  2623    A1    B0    C2    D1      0    E1    F2  102100\n",
       "2624  2624    A0    B0    C8    D1      0    E1    F2  129300\n",
       "2625  2625    A0    B0    C7    D1    100    E1    F2  275300\n",
       "2626  2626    A0    B0   C11    D1    100    E1    F2  150000\n",
       "2627  2627    A0    B0    C2    D1    100    E1    F2  191475\n",
       "\n",
       "[2628 rows x 9 columns]"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "b0c2281b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_5</th>\n",
       "      <th>y</th>\n",
       "      <th>col_0_0</th>\n",
       "      <th>col_0_1</th>\n",
       "      <th>col_0_2</th>\n",
       "      <th>col_0_3</th>\n",
       "      <th>col_1_0</th>\n",
       "      <th>col_1_1</th>\n",
       "      <th>col_1_2</th>\n",
       "      <th>col_1_3</th>\n",
       "      <th>col_4_0</th>\n",
       "      <th>col_4_1</th>\n",
       "      <th>col_6_0</th>\n",
       "      <th>col_6_1</th>\n",
       "      <th>col_6_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.223364</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>237000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.277017</td>\n",
       "      <td>0.044140</td>\n",
       "      <td>0.046043</td>\n",
       "      <td>86193</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.022451</td>\n",
       "      <td>0.023212</td>\n",
       "      <td>0.021689</td>\n",
       "      <td>169200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.277017</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>58000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002664</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>235000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>0.223364</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>102100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>129300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>0.028919</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>275300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>0.277017</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>0.223364</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>191475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2628 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         col_2     col_3     col_5       y  col_0_0  col_0_1  col_0_2  \\\n",
       "0     0.223364  0.796423  0.806697  237000      0.0      0.0      0.0   \n",
       "1     0.277017  0.044140  0.046043   86193      1.0      0.0      0.0   \n",
       "2     0.022451  0.023212  0.021689  169200      0.0      0.0      0.0   \n",
       "3     0.277017  0.796423  0.806697   58000      0.0      1.0      0.0   \n",
       "4     0.002664  0.796423  0.806697  235000      0.0      0.0      0.0   \n",
       "...        ...       ...       ...     ...      ...      ...      ...   \n",
       "2623  0.223364  0.796423  0.806697  102100      1.0      0.0      0.0   \n",
       "2624  0.001142  0.796423  0.806697  129300      0.0      0.0      0.0   \n",
       "2625  0.028919  0.796423  0.806697  275300      0.0      0.0      0.0   \n",
       "2626  0.277017  0.796423  0.806697  150000      0.0      0.0      0.0   \n",
       "2627  0.223364  0.796423  0.806697  191475      0.0      0.0      0.0   \n",
       "\n",
       "      col_0_3  col_1_0  col_1_1  col_1_2  col_1_3  col_4_0  col_4_1  col_6_0  \\\n",
       "0         0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "1         0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "2         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3         0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "4         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "2623      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2624      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2625      0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "2626      0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "2627      0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "\n",
       "      col_6_1  col_6_2  \n",
       "0         1.0      0.0  \n",
       "1         1.0      0.0  \n",
       "2         1.0      0.0  \n",
       "3         1.0      0.0  \n",
       "4         1.0      0.0  \n",
       "...       ...      ...  \n",
       "2623      1.0      0.0  \n",
       "2624      1.0      0.0  \n",
       "2625      1.0      0.0  \n",
       "2626      1.0      0.0  \n",
       "2627      1.0      0.0  \n",
       "\n",
       "[2628 rows x 17 columns]"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_categorical_data(df, high_cardinality_cols, low_cardinality_cols):\n",
    "    \"\"\"\n",
    "    Transform categorical data in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the data.\n",
    "    - high_cardinality_cols: List of column names with high cardinality (more than 50 classes).\n",
    "    - low_cardinality_cols: List of column names with low cardinality (3-4 classes).\n",
    "\n",
    "    Returns:\n",
    "    - Transformed DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copy the original DataFrame to avoid modifying it\n",
    "    transformed_df = df.copy()\n",
    "    \n",
    "    # One-Hot Encoding for low cardinality features\n",
    "    for col in low_cardinality_cols:\n",
    "        encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "        encoded_features = encoder.fit_transform(transformed_df[col].values.reshape(-1, 1))\n",
    "        encoded_df = pd.DataFrame(encoded_features, columns=[f'{col}_{i}' for i in range(encoded_features.shape[1])])\n",
    "        transformed_df = pd.concat([transformed_df, encoded_df], axis=1)\n",
    "        transformed_df.drop(col, axis=1, inplace=True)\n",
    "    \n",
    "    # Frequency Encoding for high cardinality features\n",
    "    for col in high_cardinality_cols:\n",
    "        frequency_mapping = df[col].value_counts(normalize=True).to_dict()\n",
    "        transformed_df[col] = transformed_df[col].map(frequency_mapping)\n",
    "    \n",
    "    return transformed_df\n",
    "\n",
    "df = df.drop('UID', axis=1)\n",
    "highCols = ['col_2', 'col_3', 'col_5']\n",
    "loswCols = ['col_0', 'col_1', 'col_4', 'col_6']\n",
    "\n",
    "transformed_df = transform_categorical_data(df, highCols, loswCols)\n",
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "6e4d34a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_2 : [0.22336377 0.27701674 0.02245053 0.00266362 0.15829528 0.00342466\n",
      " 0.02891933 0.07762557 0.00228311 0.00076104 0.00038052 0.02929985\n",
      " 0.00190259 0.00152207 0.00761035 0.01674277 0.00989346 0.00418569\n",
      " 0.00494673 0.00951294 0.01445967 0.00114155 0.00684932 0.00304414\n",
      " 0.00380518 0.00532725]\n",
      "col_3 : [7.96423135e-01 4.41400304e-02 2.32115677e-02 3.80517504e-03\n",
      " 2.28310502e-02 1.14155251e-03 8.75190259e-03 2.05479452e-02\n",
      " 1.90258752e-03 7.61035008e-04 3.80517504e-04 5.70776256e-03\n",
      " 2.66362253e-03 1.52207002e-03 4.18569254e-03 2.28310502e-03\n",
      " 1.29375951e-02 3.42465753e-03]\n",
      "col_5 : [8.06697108e-01 4.60426180e-02 2.16894977e-02 2.66362253e-03\n",
      " 2.35920852e-02 3.04414003e-03 7.99086758e-03 1.67427702e-02\n",
      " 1.90258752e-03 3.80517504e-04 7.61035008e-04 4.56621005e-03\n",
      " 1.14155251e-03 2.28310502e-03 3.80517504e-03 1.44596651e-02\n",
      " 1.52207002e-03]\n",
      "y : [237000  86193 169200  58000 235000 170000 183600 100000 175000 136000\n",
      "  55685 120000 150000 152000  72000 140000 130000 248400 212200 127467\n",
      " 129000 201000  40000 270703 139000 180000  62649 189650  40570  12103\n",
      "   9727 105000 187000 128000  17684  20000 139500 145000 200100 104000\n",
      "  29751 102663 210000 168400 280700 191475  60000 260000 204500 236000\n",
      " 211500  78000 165000   7799  50432 153667 323300 110820  36773 210914\n",
      " 155000 195400 111775 148800  52533 225000 153000  75000   9272 159100\n",
      " 156400 135000 115000 190000  96100 172000 110600 285800 195652  21669\n",
      " 191200 109400 201450 228000 144000 240500 156600  59020 176000 147100\n",
      " 160000 276000  95000 275000  49253 105200 141525  70000 155850   8000\n",
      " 114500  40038  85066 200000 177000  51039 280000  85000 161311  48609\n",
      " 185000 247500 250000  15806 132100  89306  14307 186000  79833  55000\n",
      " 110000 153600 128058 168000  88256 124000 125000  15000 213580 193900\n",
      " 105500 122600 151902 275300 106000  60795 182750  90734  83000  34672\n",
      " 126000 157000 165220 122500 192500  46000 113000  86000 163800 220000\n",
      " 206000  90000 103691  80000 192600 142200  73880   6359  78990  18907\n",
      " 154000  24165  93918 188800  18000  81500 213660 169000 131300 240000\n",
      " 141600 122000 127000 104611 174000  50000 101570  66000 104500  65488\n",
      " 129300 141300  66970 134760 148750 209100 106500  45390 148700  61896\n",
      "  84053  61566 185900 179820  20984 175100 102500  92350  64090   6270\n",
      " 288000  81666 160288  72212 183500  85500 108000 167500  48289 105400\n",
      " 130240  33808  98506 119000  85847 179400 149600 121700 133832  38631\n",
      " 136100 182160 112000 230000 132320 137500 126500  22611 195000 416000\n",
      " 146000  76833  80481 205000   9289 167000 164000 205920 324000  73546\n",
      "  81000 102100 249500 202000 222200 208450  82000 102640 183310  40481\n",
      " 138750 128875  51753 109024 174500 207000 236900  33000 269000 143865\n",
      "  65666 128750 116000 183000 172309 130026 178800 216000 124234 151410\n",
      " 215000 423000  63040 195700 123405 252000  77262  98000 194500 112872\n",
      " 184000 172200  40777 231250 198800  52500 245100 219000  45760  37824\n",
      " 145885  50180 149040 225900 110037  42533 109280 200160  63312 173762\n",
      " 172800 153400  63000  87000 180180  68293  47280 144100 120250  67597\n",
      "  70186  13989  83171 284310 226700 115092 143200 133766 260500 143100\n",
      "  97218  93800 188000 195895  68400  75116  92000  69751 208000 202800\n",
      "  38400 198200 148000 196200  55800  12000 309400  69999  84000  66837\n",
      " 109000 350000  67723 136620  49268  99000 115500 310000  30000  59102\n",
      " 297300  17509 113750  42026 145900  60761 161800  26005  21844 258000\n",
      " 115440  79000 160080  38000 110500  62000  20171  66531 318300 147800\n",
      " 196000 234100 152500  45555 121600  65257 133300 106800 126080 170550\n",
      " 121500 121523  83500 106250  31520  75050 152900 300000 203300  87738\n",
      "  68318  73900  73000  56536  33609  31795 142800  74178  48000  61989\n",
      "  61800 100706 151800  28609 189750  82528  35093 220110  42197 265000\n",
      " 185700  99750 241000 101228 149850  38776 217000 317070  93700  65062\n",
      "  85700 216200 245000 253750 193000 300240 157750 117104  24823  12888\n",
      " 104890 199000  90700   6304 289800  25000  94564  72200  51508 161342\n",
      "  75344 115573  28369  75648  55410 134000  74540 115447 149076  77300\n",
      " 197000 171250 192400  97750 141288  43096  42000 112900  16228  64500\n",
      "  18238  72914  82365 116914 100500  62726  24000  57723  71907   5132\n",
      " 167580  74000  76309  53654   9466 212800  43809 172600 150075  44365\n",
      " 194000 203500 119300 179305  60757 189110 173000 250500  51081 154600\n",
      "  79197 159200  22800 162500 231500  60093  68428  51321 205600 110446\n",
      " 227000 122700 159832  46759  40663 259000 127221 177500  60938 119059\n",
      " 297500 223250  36259 376080 117000 213120  53416 236600 188700  91237\n",
      "  67141  46809 147000  92700 176100 215300  28399 128500 222000  46597\n",
      " 123000  88654 178600  24342  95746  65000  38154 115934 145828 208775\n",
      "  28368  47899 109371 239748 132300  39916  99100 158200 262500 222640\n",
      " 192000 102000  94300  41689 134236 184700 248700 125600  82280 325000\n",
      " 129400 132000  37558  94665 104697 128280  70500 182200 112300 229998\n",
      " 140800  54094  34320 136994 304000 243225  54000 286000  10000  53192\n",
      "  19073 229000 141290 213000 113900 164996 115222 239000 101943  90320\n",
      "  12767   7000 158677 380000  58331 106020  45618  17805 136260 293000\n",
      "  70139 195800  16904  25500 148500  89200 269600  94000 353200 212750\n",
      " 178750 198440 100800 253200 370000 166000 141846 272550  46178 243000\n",
      " 162000  61200  76814  45896 187500 140250 179975 127075  80036 107000\n",
      " 172386  15966  64385 209450 142000 150260 104650 143860  28016 243900\n",
      "  21461 246000  98200 257000  77684 175308  39925 146300  19609 102772\n",
      "  12877  37825  76958  60400 248100  80041 221300  88100 170500  30523\n",
      "  93000 140400   5679  12608   5409  96282 139600  54634 171000 166700\n",
      " 188100 193750 238000 206500  54685  69133  21013 340000 221000  75020\n",
      "  66022 134024 105700  51716 198000 314100 161000 116100 197430 249260\n",
      " 375000 385000 138900  96113 144200 153090  45391  67000 123700 156000\n",
      " 179775 192564  57872  18053 256000  66265 144854  56256  13493 227200\n",
      " 125404  58837 104300 115360  65013  99703  66100 138000  51962   5723\n",
      " 247300 224000 133200  71786 215050 145300 133000  25216 342300 154545\n",
      "  87980  95550 203100 114000  45050 159500  29453  21637 168100 203000\n",
      "  59888  71897  52008 181940 116450 137400 155499 130800 291500  61300\n",
      " 262000 133800 146200 105066 179000 206699  64980  17022  61467 219535\n",
      "   6072  23000 182500 289076  57000 107309 124500  19522 105236 138600\n",
      " 178500  82500 192037  72946 135446 123400 124740 214618 188500  82744\n",
      " 191765  99450  63900  42923 161500  91000   5707 255000 159000 109006\n",
      " 299500 121093 110925  52000 342810 202353 102839  33511 114047  56723\n",
      " 190200 165750 163625 167100 127599  51000 270000  20670  63192  56000\n",
      "  68000  63831 204100 120160 106260  89294 156868 172500  13400  22892\n",
      "  16414  94500 175950 158000 120600 107900 116150  24740 223800  28476\n",
      " 139860 105380  25532  86466  36000 214000]\n",
      "col_0_0 : [0. 1.]\n",
      "col_0_1 : [0. 1.]\n",
      "col_0_2 : [0. 1.]\n",
      "col_0_3 : [0. 1.]\n",
      "col_1_0 : [0. 1.]\n",
      "col_1_1 : [0. 1.]\n",
      "col_1_2 : [0. 1.]\n",
      "col_1_3 : [0. 1.]\n",
      "col_4_0 : [0. 1.]\n",
      "col_4_1 : [1. 0.]\n",
      "col_6_0 : [0. 1.]\n",
      "col_6_1 : [1. 0.]\n",
      "col_6_2 : [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for col in transformed_df.columns:\n",
    "    print(f\"{col} : {transformed_df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b8758b",
   "metadata": {},
   "source": [
    "### Imputing Missing Values\n",
    "\n",
    "There are 6 categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "4887a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_cols = ['col_0', 'col_1','col_2','col_3','col_5','col_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "ce768ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Calculate the mode (most frequent value) of the column\\nfor col in cols:\\n    mode_value = df[col].mode()[0]\\n    print(mode_value)\\n    df[col].fillna(mode_value, inplace=True)\\n\\n# Fill missing values with the mode\\ndf['column_name'].fillna(mode_value, inplace=True)\""
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Calculate the mode (most frequent value) of the column\n",
    "for col in cols:\n",
    "    mode_value = df[col].mode()[0]\n",
    "    print(mode_value)\n",
    "    df[col].fillna(mode_value, inplace=True)\n",
    "\n",
    "# Fill missing values with the mode\n",
    "df['column_name'].fillna(mode_value, inplace=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "13dd9576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col_0    139\n",
       "col_1     86\n",
       "col_2      0\n",
       "col_3      0\n",
       "col_4      0\n",
       "col_5      0\n",
       "col_6    112\n",
       "y          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "c3d57afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C2</td>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>237000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1</td>\n",
       "      <td>B0</td>\n",
       "      <td>C11</td>\n",
       "      <td>D4</td>\n",
       "      <td>100</td>\n",
       "      <td>E4</td>\n",
       "      <td>F2</td>\n",
       "      <td>86193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C18</td>\n",
       "      <td>D0</td>\n",
       "      <td>0</td>\n",
       "      <td>E0</td>\n",
       "      <td>F2</td>\n",
       "      <td>169200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2</td>\n",
       "      <td>B0</td>\n",
       "      <td>C11</td>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C67</td>\n",
       "      <td>D1</td>\n",
       "      <td>0</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>A1</td>\n",
       "      <td>B0</td>\n",
       "      <td>C2</td>\n",
       "      <td>D1</td>\n",
       "      <td>0</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C8</td>\n",
       "      <td>D1</td>\n",
       "      <td>0</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>129300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C7</td>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>275300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C11</td>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C2</td>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>191475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2628 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     col_0 col_1 col_2 col_3  col_4 col_5 col_6       y\n",
       "0       A0    B0    C2    D1    100    E1    F2  237000\n",
       "1       A1    B0   C11    D4    100    E4    F2   86193\n",
       "2       A0    B0   C18    D0      0    E0    F2  169200\n",
       "3       A2    B0   C11    D1    100    E1    F2   58000\n",
       "4       A0    B0   C67    D1      0    E1    F2  235000\n",
       "...    ...   ...   ...   ...    ...   ...   ...     ...\n",
       "2623    A1    B0    C2    D1      0    E1    F2  102100\n",
       "2624    A0    B0    C8    D1      0    E1    F2  129300\n",
       "2625    A0    B0    C7    D1    100    E1    F2  275300\n",
       "2626    A0    B0   C11    D1    100    E1    F2  150000\n",
       "2627    A0    B0    C2    D1    100    E1    F2  191475\n",
       "\n",
       "[2628 rows x 8 columns]"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "8b571f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0 : ['A0' 'A1' 'A2' nan 'A3']\n",
      "col_1 : ['B0' nan 'B2' 'B3' 'B1']\n",
      "col_2 : ['C2' 'C11' 'C18' 'C67' 'C4' 'C52' 'C7' 'C36' 'C57' 'C9' 'C54' 'C41' 'C44'\n",
      " 'C15' 'C39' 'C40' 'C59' 'C27' 'C29' 'C3' 'C49' 'C33' 'C6' 'C53' 'C12'\n",
      " 'C1' 'C56' 'C30' 'C81' 'C26' 'C35' 'C22' 'C34' 'C58' 'C21' 'C47' 'C20'\n",
      " 'C28' 'C50' 'C89' 'C62' 'C92' 'C38' 'C19' 'C0' 'C70' 'C87' 'C69' 'C76'\n",
      " 'C48' 'C55' 'C85' 'C17' 'C25' 'C16' 'C63' 'C13' 'C46' 'C37' 'C90' 'C86'\n",
      " 'C31' 'C71' 'C83' 'C45' 'C61' 'C23' 'C88' 'C24' 'C51' 'C72' 'C65' 'C60'\n",
      " 'C64' 'C82' 'C68' 'C79' 'C5' 'C10' 'C77' 'C42' 'C43' 'C75' 'C8' 'C91'\n",
      " 'C80' 'C74' 'C14' 'C78' 'C66']\n",
      "col_3 : ['D1' 'D4' 'D0' 'D8' 'D2' 'D41' 'D12' 'D6' 'D53' 'D48' 'D66' 'D26' 'D42'\n",
      " 'D36' 'D68' 'D54' 'D9' 'D5' 'D55' 'D3' 'D75' 'D21' 'D24' 'D40' 'D16'\n",
      " 'D39' 'D58' 'D71' 'D32' 'D72' 'D15' 'D13' 'D31' 'D51' 'D76' 'D20' 'D22'\n",
      " 'D46' 'D10' 'D29' 'D19' 'D56' 'D62' 'D7' 'D23' 'D34' 'D38' 'D77' 'D64'\n",
      " 'D14' 'D60' 'D37' 'D44' 'D28' 'D45' 'D59' 'D47' 'D11' 'D30' 'D18' 'D27'\n",
      " 'D49' 'D33' 'D57' 'D35' 'D50' 'D65' 'D73']\n",
      "col_4 : [100   0  50]\n",
      "col_5 : ['E1' 'E4' 'E0' 'E24' 'E2' 'E19' 'E11' 'E6' 'E52' 'E48' 'E63' 'E36' 'E23'\n",
      " 'E40' 'E32' 'E38' 'E18' 'E69' 'E8' 'E53' 'E3' 'E70' 'E5' 'E22' 'E45'\n",
      " 'E14' 'E35' 'E29' 'E67' 'E13' 'E28' 'E51' 'E61' 'E17' 'E20' 'E47' 'E12'\n",
      " 'E9' 'E49' 'E54' 'E60' 'E7' 'E21' 'E30' 'E34' 'E71' 'E64' 'E59' 'E33'\n",
      " 'E56' 'E43' 'E27' 'E25' 'E15' 'E58' 'E57' 'E46' 'E10' 'E16' 'E37' 'E26'\n",
      " 'E50' 'E42' 'E41' 'E44' 'E31' 'E62']\n",
      "col_6 : ['F2' 'F0' 'F1' nan]\n",
      "y : [237000  86193 169200  58000 235000 170000 183600 100000 175000 136000\n",
      "  55685 120000 150000 152000  72000 140000 130000 248400 212200 127467\n",
      " 129000 201000  40000 270703 139000 180000  62649 189650  40570  12103\n",
      "   9727 105000 187000 128000  17684  20000 139500 145000 200100 104000\n",
      "  29751 102663 210000 168400 280700 191475  60000 260000 204500 236000\n",
      " 211500  78000 165000   7799  50432 153667 323300 110820  36773 210914\n",
      " 155000 195400 111775 148800  52533 225000 153000  75000   9272 159100\n",
      " 156400 135000 115000 190000  96100 172000 110600 285800 195652  21669\n",
      " 191200 109400 201450 228000 144000 240500 156600  59020 176000 147100\n",
      " 160000 276000  95000 275000  49253 105200 141525  70000 155850   8000\n",
      " 114500  40038  85066 200000 177000  51039 280000  85000 161311  48609\n",
      " 185000 247500 250000  15806 132100  89306  14307 186000  79833  55000\n",
      " 110000 153600 128058 168000  88256 124000 125000  15000 213580 193900\n",
      " 105500 122600 151902 275300 106000  60795 182750  90734  83000  34672\n",
      " 126000 157000 165220 122500 192500  46000 113000  86000 163800 220000\n",
      " 206000  90000 103691  80000 192600 142200  73880   6359  78990  18907\n",
      " 154000  24165  93918 188800  18000  81500 213660 169000 131300 240000\n",
      " 141600 122000 127000 104611 174000  50000 101570  66000 104500  65488\n",
      " 129300 141300  66970 134760 148750 209100 106500  45390 148700  61896\n",
      "  84053  61566 185900 179820  20984 175100 102500  92350  64090   6270\n",
      " 288000  81666 160288  72212 183500  85500 108000 167500  48289 105400\n",
      " 130240  33808  98506 119000  85847 179400 149600 121700 133832  38631\n",
      " 136100 182160 112000 230000 132320 137500 126500  22611 195000 416000\n",
      " 146000  76833  80481 205000   9289 167000 164000 205920 324000  73546\n",
      "  81000 102100 249500 202000 222200 208450  82000 102640 183310  40481\n",
      " 138750 128875  51753 109024 174500 207000 236900  33000 269000 143865\n",
      "  65666 128750 116000 183000 172309 130026 178800 216000 124234 151410\n",
      " 215000 423000  63040 195700 123405 252000  77262  98000 194500 112872\n",
      " 184000 172200  40777 231250 198800  52500 245100 219000  45760  37824\n",
      " 145885  50180 149040 225900 110037  42533 109280 200160  63312 173762\n",
      " 172800 153400  63000  87000 180180  68293  47280 144100 120250  67597\n",
      "  70186  13989  83171 284310 226700 115092 143200 133766 260500 143100\n",
      "  97218  93800 188000 195895  68400  75116  92000  69751 208000 202800\n",
      "  38400 198200 148000 196200  55800  12000 309400  69999  84000  66837\n",
      " 109000 350000  67723 136620  49268  99000 115500 310000  30000  59102\n",
      " 297300  17509 113750  42026 145900  60761 161800  26005  21844 258000\n",
      " 115440  79000 160080  38000 110500  62000  20171  66531 318300 147800\n",
      " 196000 234100 152500  45555 121600  65257 133300 106800 126080 170550\n",
      " 121500 121523  83500 106250  31520  75050 152900 300000 203300  87738\n",
      "  68318  73900  73000  56536  33609  31795 142800  74178  48000  61989\n",
      "  61800 100706 151800  28609 189750  82528  35093 220110  42197 265000\n",
      " 185700  99750 241000 101228 149850  38776 217000 317070  93700  65062\n",
      "  85700 216200 245000 253750 193000 300240 157750 117104  24823  12888\n",
      " 104890 199000  90700   6304 289800  25000  94564  72200  51508 161342\n",
      "  75344 115573  28369  75648  55410 134000  74540 115447 149076  77300\n",
      " 197000 171250 192400  97750 141288  43096  42000 112900  16228  64500\n",
      "  18238  72914  82365 116914 100500  62726  24000  57723  71907   5132\n",
      " 167580  74000  76309  53654   9466 212800  43809 172600 150075  44365\n",
      " 194000 203500 119300 179305  60757 189110 173000 250500  51081 154600\n",
      "  79197 159200  22800 162500 231500  60093  68428  51321 205600 110446\n",
      " 227000 122700 159832  46759  40663 259000 127221 177500  60938 119059\n",
      " 297500 223250  36259 376080 117000 213120  53416 236600 188700  91237\n",
      "  67141  46809 147000  92700 176100 215300  28399 128500 222000  46597\n",
      " 123000  88654 178600  24342  95746  65000  38154 115934 145828 208775\n",
      "  28368  47899 109371 239748 132300  39916  99100 158200 262500 222640\n",
      " 192000 102000  94300  41689 134236 184700 248700 125600  82280 325000\n",
      " 129400 132000  37558  94665 104697 128280  70500 182200 112300 229998\n",
      " 140800  54094  34320 136994 304000 243225  54000 286000  10000  53192\n",
      "  19073 229000 141290 213000 113900 164996 115222 239000 101943  90320\n",
      "  12767   7000 158677 380000  58331 106020  45618  17805 136260 293000\n",
      "  70139 195800  16904  25500 148500  89200 269600  94000 353200 212750\n",
      " 178750 198440 100800 253200 370000 166000 141846 272550  46178 243000\n",
      " 162000  61200  76814  45896 187500 140250 179975 127075  80036 107000\n",
      " 172386  15966  64385 209450 142000 150260 104650 143860  28016 243900\n",
      "  21461 246000  98200 257000  77684 175308  39925 146300  19609 102772\n",
      "  12877  37825  76958  60400 248100  80041 221300  88100 170500  30523\n",
      "  93000 140400   5679  12608   5409  96282 139600  54634 171000 166700\n",
      " 188100 193750 238000 206500  54685  69133  21013 340000 221000  75020\n",
      "  66022 134024 105700  51716 198000 314100 161000 116100 197430 249260\n",
      " 375000 385000 138900  96113 144200 153090  45391  67000 123700 156000\n",
      " 179775 192564  57872  18053 256000  66265 144854  56256  13493 227200\n",
      " 125404  58837 104300 115360  65013  99703  66100 138000  51962   5723\n",
      " 247300 224000 133200  71786 215050 145300 133000  25216 342300 154545\n",
      "  87980  95550 203100 114000  45050 159500  29453  21637 168100 203000\n",
      "  59888  71897  52008 181940 116450 137400 155499 130800 291500  61300\n",
      " 262000 133800 146200 105066 179000 206699  64980  17022  61467 219535\n",
      "   6072  23000 182500 289076  57000 107309 124500  19522 105236 138600\n",
      " 178500  82500 192037  72946 135446 123400 124740 214618 188500  82744\n",
      " 191765  99450  63900  42923 161500  91000   5707 255000 159000 109006\n",
      " 299500 121093 110925  52000 342810 202353 102839  33511 114047  56723\n",
      " 190200 165750 163625 167100 127599  51000 270000  20670  63192  56000\n",
      "  68000  63831 204100 120160 106260  89294 156868 172500  13400  22892\n",
      "  16414  94500 175950 158000 120600 107900 116150  24740 223800  28476\n",
      " 139860 105380  25532  86466  36000 214000]\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"{col} : {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "1e470566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0    1679\n",
      "A1     542\n",
      "A2     195\n",
      "A3      73\n",
      "Name: col_0, dtype: int64\n",
      "B0    2518\n",
      "B3      11\n",
      "B2       7\n",
      "B1       6\n",
      "Name: col_1, dtype: int64\n",
      "C11    728\n",
      "C2     587\n",
      "C4     416\n",
      "C9     204\n",
      "C15     77\n",
      "      ... \n",
      "C62      1\n",
      "C63      1\n",
      "C92      1\n",
      "C76      1\n",
      "C66      1\n",
      "Name: col_2, Length: 90, dtype: int64\n",
      "D1     2093\n",
      "D4      116\n",
      "D0       61\n",
      "D2       60\n",
      "D6       54\n",
      "       ... \n",
      "D32       1\n",
      "D71       1\n",
      "D75       1\n",
      "D66       1\n",
      "D73       1\n",
      "Name: col_3, Length: 68, dtype: int64\n",
      "E1     2120\n",
      "E4      121\n",
      "E2       62\n",
      "E0       57\n",
      "E6       44\n",
      "       ... \n",
      "E45       1\n",
      "E47       1\n",
      "E20       1\n",
      "E67       1\n",
      "E62       1\n",
      "Name: col_5, Length: 67, dtype: int64\n",
      "F2    2104\n",
      "F0     309\n",
      "F1     103\n",
      "Name: col_6, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in cat_cols:\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "d8b38097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"highCategoryCOlumns = ['col_2', 'col_3', 'col_5']\\nfor col in highCategoryCOlumns:\\n    frequency_mapping = df[col].value_counts().to_dict()\\n    df[col] = df[col].map(frequency_mapping)\\n\\nfor col in highCategoryCOlumns:\\n    print(df[col].value_counts())\""
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"highCategoryCOlumns = ['col_2', 'col_3', 'col_5']\n",
    "for col in highCategoryCOlumns:\n",
    "    frequency_mapping = df[col].value_counts().to_dict()\n",
    "    df[col] = df[col].map(frequency_mapping)\n",
    "\n",
    "for col in highCategoryCOlumns:\n",
    "    print(df[col].value_counts())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "13729370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lowCategoryCols = [\\'col_0\\', \\'col_1\\', \"col_6\"]\\nle = LabelEncoder()\\n\\nfor col in lowCategoryCols:\\n    df[col] = le.fit_transform(df[col])'"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"lowCategoryCols = ['col_0', 'col_1', \"col_6\"]\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in lowCategoryCols:\n",
    "    df[col] = le.fit_transform(df[col])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "ba117709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col_0    139\n",
       "col_1     86\n",
       "col_2      0\n",
       "col_3      0\n",
       "col_4      0\n",
       "col_5      0\n",
       "col_6    112\n",
       "y          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "b68c48ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_5</th>\n",
       "      <th>y</th>\n",
       "      <th>col_0_0</th>\n",
       "      <th>col_0_1</th>\n",
       "      <th>col_0_2</th>\n",
       "      <th>col_0_3</th>\n",
       "      <th>col_1_0</th>\n",
       "      <th>col_1_1</th>\n",
       "      <th>col_1_2</th>\n",
       "      <th>col_1_3</th>\n",
       "      <th>col_4_0</th>\n",
       "      <th>col_4_1</th>\n",
       "      <th>col_6_0</th>\n",
       "      <th>col_6_1</th>\n",
       "      <th>col_6_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2628.000000</td>\n",
       "      <td>2628.000000</td>\n",
       "      <td>2628.000000</td>\n",
       "      <td>2628.000000</td>\n",
       "      <td>2628.000000</td>\n",
       "      <td>2628.000000</td>\n",
       "      <td>2628.000000</td>\n",
       "      <td>2628.000000</td>\n",
       "      <td>2628.000000</td>\n",
       "      <td>2628.000000</td>\n",
       "      <td>2628.000000</td>\n",
       "      <td>2628.000000</td>\n",
       "      <td>2628.000000</td>\n",
       "      <td>2628.000000</td>\n",
       "      <td>2628.000000</td>\n",
       "      <td>2628.000000</td>\n",
       "      <td>2628.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.161005</td>\n",
       "      <td>0.638120</td>\n",
       "      <td>0.654578</td>\n",
       "      <td>137642.657154</td>\n",
       "      <td>0.206240</td>\n",
       "      <td>0.074201</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.052892</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.002664</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>0.032725</td>\n",
       "      <td>0.051750</td>\n",
       "      <td>0.437215</td>\n",
       "      <td>0.039193</td>\n",
       "      <td>0.800609</td>\n",
       "      <td>0.042618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.104831</td>\n",
       "      <td>0.313251</td>\n",
       "      <td>0.310903</td>\n",
       "      <td>62886.926575</td>\n",
       "      <td>0.404682</td>\n",
       "      <td>0.262147</td>\n",
       "      <td>0.164367</td>\n",
       "      <td>0.223860</td>\n",
       "      <td>0.047736</td>\n",
       "      <td>0.051551</td>\n",
       "      <td>0.064574</td>\n",
       "      <td>0.177948</td>\n",
       "      <td>0.221565</td>\n",
       "      <td>0.496137</td>\n",
       "      <td>0.194092</td>\n",
       "      <td>0.399619</td>\n",
       "      <td>0.202033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>5132.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.029300</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>95000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.223364</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>135000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.277017</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>176325.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.277017</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>423000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             col_2        col_3        col_5              y      col_0_0  \\\n",
       "count  2628.000000  2628.000000  2628.000000    2628.000000  2628.000000   \n",
       "mean      0.161005     0.638120     0.654578  137642.657154     0.206240   \n",
       "std       0.104831     0.313251     0.310903   62886.926575     0.404682   \n",
       "min       0.000381     0.000381     0.000381    5132.000000     0.000000   \n",
       "25%       0.029300     0.796423     0.806697   95000.000000     0.000000   \n",
       "50%       0.223364     0.796423     0.806697  135000.000000     0.000000   \n",
       "75%       0.277017     0.796423     0.806697  176325.000000     0.000000   \n",
       "max       0.277017     0.796423     0.806697  423000.000000     1.000000   \n",
       "\n",
       "           col_0_1      col_0_2      col_0_3      col_1_0      col_1_1  \\\n",
       "count  2628.000000  2628.000000  2628.000000  2628.000000  2628.000000   \n",
       "mean      0.074201     0.027778     0.052892     0.002283     0.002664   \n",
       "std       0.262147     0.164367     0.223860     0.047736     0.051551   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "           col_1_2      col_1_3      col_4_0      col_4_1      col_6_0  \\\n",
       "count  2628.000000  2628.000000  2628.000000  2628.000000  2628.000000   \n",
       "mean      0.004186     0.032725     0.051750     0.437215     0.039193   \n",
       "std       0.064574     0.177948     0.221565     0.496137     0.194092   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "           col_6_1      col_6_2  \n",
       "count  2628.000000  2628.000000  \n",
       "mean      0.800609     0.042618  \n",
       "std       0.399619     0.202033  \n",
       "min       0.000000     0.000000  \n",
       "25%       1.000000     0.000000  \n",
       "50%       1.000000     0.000000  \n",
       "75%       1.000000     0.000000  \n",
       "max       1.000000     1.000000  "
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "1d48cb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 16))\n",
    "transformed_df.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "ab9f2a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 16))\n",
    "transformed_df.boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "3a38c425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 16))\n",
    "transformed_df.plot.kde()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "ed509369",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transformed_df.drop('y', axis=1)\n",
    "y = transformed_df['y']\n",
    "\n",
    "# Create polynomial features (e.g., up to the 3rd degree)\n",
    "degree = 5\n",
    "poly_features = PolynomialFeatures(degree=degree)\n",
    "X_poly = poly_features.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "98aa1ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "Linear Regression - Root Mean Squared Error: 1495757845774242.00\n",
      "Linear Regression - R-squared: -497611245582962917376.00\n",
      "\n",
      "Ridge Regression:\n",
      "Ridge Regression - Root Mean Squared Error: 54717.40\n",
      "Ridge Regression - R-squared: 0.33\n",
      "\n",
      "Lasso Regression:\n",
      "Lasso Regression - Root Mean Squared Error: 54638.23\n",
      "Lasso Regression - R-squared: 0.34\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train, y_train)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_reg = Ridge(alpha=10.0, max_iter=50000)  # You can adjust the regularization strength (alpha)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_reg = Lasso(alpha=10.0, max_iter=50000)  # You can adjust the regularization strength (alpha)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_linear = linear_reg.predict(X_test)\n",
    "y_pred_ridge = ridge_reg.predict(X_test)\n",
    "y_pred_lasso = lasso_reg.predict(X_test)\n",
    "\n",
    "# Evaluate models\n",
    "def evaluate_model(model, y_true, y_pred, name):\n",
    "    mse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"{name} - Root Mean Squared Error: {mse:.2f}\")\n",
    "    print(f\"{name} - R-squared: {r2:.2f}\")\n",
    "\n",
    "print(\"Linear Regression:\")\n",
    "evaluate_model(linear_reg, y_test, y_pred_linear, \"Linear Regression\")\n",
    "\n",
    "print(\"\\nRidge Regression:\")\n",
    "evaluate_model(ridge_reg, y_test, y_pred_ridge, \"Ridge Regression\")\n",
    "\n",
    "print(\"\\nLasso Regression:\")\n",
    "evaluate_model(lasso_reg, y_test, y_pred_lasso, \"Lasso Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "49f609ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_5</th>\n",
       "      <th>y</th>\n",
       "      <th>col_0_0</th>\n",
       "      <th>col_0_1</th>\n",
       "      <th>col_0_2</th>\n",
       "      <th>col_0_3</th>\n",
       "      <th>col_1_0</th>\n",
       "      <th>col_1_1</th>\n",
       "      <th>col_1_2</th>\n",
       "      <th>col_1_3</th>\n",
       "      <th>col_4_0</th>\n",
       "      <th>col_4_1</th>\n",
       "      <th>col_6_0</th>\n",
       "      <th>col_6_1</th>\n",
       "      <th>col_6_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.223364</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>237000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.277017</td>\n",
       "      <td>0.044140</td>\n",
       "      <td>0.046043</td>\n",
       "      <td>86193</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.022451</td>\n",
       "      <td>0.023212</td>\n",
       "      <td>0.021689</td>\n",
       "      <td>169200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.277017</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>58000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002664</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>235000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>0.223364</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>102100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>129300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>0.028919</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>275300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>0.277017</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>0.223364</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>191475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2628 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         col_2     col_3     col_5       y  col_0_0  col_0_1  col_0_2  \\\n",
       "0     0.223364  0.796423  0.806697  237000      0.0      0.0      0.0   \n",
       "1     0.277017  0.044140  0.046043   86193      1.0      0.0      0.0   \n",
       "2     0.022451  0.023212  0.021689  169200      0.0      0.0      0.0   \n",
       "3     0.277017  0.796423  0.806697   58000      0.0      1.0      0.0   \n",
       "4     0.002664  0.796423  0.806697  235000      0.0      0.0      0.0   \n",
       "...        ...       ...       ...     ...      ...      ...      ...   \n",
       "2623  0.223364  0.796423  0.806697  102100      1.0      0.0      0.0   \n",
       "2624  0.001142  0.796423  0.806697  129300      0.0      0.0      0.0   \n",
       "2625  0.028919  0.796423  0.806697  275300      0.0      0.0      0.0   \n",
       "2626  0.277017  0.796423  0.806697  150000      0.0      0.0      0.0   \n",
       "2627  0.223364  0.796423  0.806697  191475      0.0      0.0      0.0   \n",
       "\n",
       "      col_0_3  col_1_0  col_1_1  col_1_2  col_1_3  col_4_0  col_4_1  col_6_0  \\\n",
       "0         0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "1         0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "2         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3         0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "4         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "2623      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2624      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2625      0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "2626      0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "2627      0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "\n",
       "      col_6_1  col_6_2  \n",
       "0         1.0      0.0  \n",
       "1         1.0      0.0  \n",
       "2         1.0      0.0  \n",
       "3         1.0      0.0  \n",
       "4         1.0      0.0  \n",
       "...       ...      ...  \n",
       "2623      1.0      0.0  \n",
       "2624      1.0      0.0  \n",
       "2625      1.0      0.0  \n",
       "2626      1.0      0.0  \n",
       "2627      1.0      0.0  \n",
       "\n",
       "[2628 rows x 17 columns]"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "1751816e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.163e+11, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.946e+11, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.953e+11, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.772e+11, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.199e+11, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.996e+11, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.800e+11, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.821e+11, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.639e+11, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.047e+11, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.918e+11, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.717e+11, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.731e+11, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.555e+11, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.977e+11, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.678e+11, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.414e+11, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.388e+11, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.189e+11, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.604e+11, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.472e+11, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.321e+11, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.278e+11, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.091e+11, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.477e+11, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.337e+11, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.270e+11, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.228e+11, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.043e+11, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.418e+11, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.150e+11, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.939e+11, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.956e+11, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.774e+11, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.194e+11, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.942e+11, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.712e+11, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.816e+11, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.606e+11, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.976e+11, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.796e+11, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.685e+11, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.734e+11, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.532e+11, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.871e+11, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.502e+11, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.472e+11, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.525e+11, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.222e+11, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.711e+11, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.298e+11, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.230e+11, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.342e+11, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.148e+11, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.487e+11, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.817e+11, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.012e+11, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.140e+11, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.982e+11, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.265e+11, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.549e+11, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.580e+11, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.561e+11, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.361e+11, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.901e+11, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.906e+11, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.935e+11, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.913e+11, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.377e+11, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.770e+11, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.925e+11, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e+11, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.652e+11, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.120e+11, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.861e+11, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.208e+11, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.802e+10, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.765e+11, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.628e+11, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.609e+10, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.229e+10, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.654e+09, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.305e+10, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.087e+10, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.566e+10, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.417e+10, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.810e+08, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.200e+10, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.175e+10, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.935e+09, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.203e+11, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.236e+11, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+11, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.696e+11, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.974e+11, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.243e+10, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.603e+11, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.810e+10, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.456e+10, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.702e+09, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.717e+09, tolerance: 1.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.883e+09, tolerance: 1.958e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.974e+08, tolerance: 1.852e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.993e+10, tolerance: 1.828e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Rittique\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.051e+08, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge Regression Parameters: Alpha = 10.0, Max Iterations = 100, RMSE = 56099.42791550674\n",
      "Best Lasso Regression Parameters: Alpha = 10.0, Max Iterations = 100, RMSE = 59265.83658735377\n"
     ]
    }
   ],
   "source": [
    "alpha_values = [0.01, 0.1, 1.0, 10.0]\n",
    "max_iter_values = [100, 500, 1000, 10000, 50000, 100000]\n",
    "\n",
    "# Initialize lists to store results\n",
    "ridge_results = []\n",
    "lasso_results = []\n",
    "\n",
    "# Perform nested cross-validation for Ridge and Lasso models\n",
    "for alpha in alpha_values:\n",
    "    for max_iter in max_iter_values:\n",
    "        # Ridge Regression\n",
    "        ridge_model = Ridge(alpha=alpha, max_iter=max_iter)\n",
    "        ridge_scores = cross_val_score(ridge_model, X_test, y_test, cv=5, scoring='neg_mean_squared_error')\n",
    "        ridge_rmse_scores = np.sqrt(-ridge_scores)\n",
    "        ridge_mean_rmse = np.mean(ridge_rmse_scores)\n",
    "        ridge_results.append((alpha, max_iter, ridge_mean_rmse))\n",
    "        \n",
    "        # Lasso Regression\n",
    "        lasso_model = Lasso(alpha=alpha, max_iter=max_iter)\n",
    "        lasso_scores = cross_val_score(lasso_model, X_test, y_test, cv=5, scoring='neg_mean_squared_error')\n",
    "        lasso_rmse_scores = np.sqrt(-lasso_scores)\n",
    "        lasso_mean_rmse = np.mean(lasso_rmse_scores)\n",
    "        lasso_results.append((alpha, max_iter, lasso_mean_rmse))\n",
    "\n",
    "# Find the best alpha and max iteration values for Ridge\n",
    "best_ridge_params = min(ridge_results, key=lambda x: x[2])\n",
    "print(f\"Best Ridge Regression Parameters: Alpha = {best_ridge_params[0]}, Max Iterations = {best_ridge_params[1]}, RMSE = {best_ridge_params[2]}\")\n",
    "\n",
    "# Find the best alpha and max iteration values for Lasso\n",
    "best_lasso_params = min(lasso_results, key=lambda x: x[2])\n",
    "print(f\"Best Lasso Regression Parameters: Alpha = {best_lasso_params[0]}, Max Iterations = {best_lasso_params[1]}, RMSE = {best_lasso_params[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "bf071404",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Models\n",
    "- Elastic Net Regression\n",
    "- Support Vector Regression (SVR)\n",
    "- Gradient Boosting Regressor\n",
    "- Random Forest Regressor\n",
    "- K-Nearest Neighbors (KNN) Regression\n",
    "- Bayesian Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "b57fdcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net Regression RMSE: 56344.08\n",
      "Elastic Net Regression R-squared: 0.29\n",
      "SVR RMSE: 65774.89\n",
      "SVR R-squared: 0.04\n",
      "Gradient Boosting RMSE: 53038.50\n",
      "Gradient Boosting R-squared: 0.37\n",
      "Random Forest RMSE: 51283.37\n",
      "Random Forest R-squared: 0.42\n",
      "KNN Regression RMSE: 56655.08\n",
      "KNN Regression R-squared: 0.29\n",
      "Bayesian Linear Regression RMSE: 54561.78\n",
      "Bayesian Linear Regression R-squared: 0.34\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet, BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Elastic Net Regression\n",
    "elastic_net_model = ElasticNet(alpha=1.0, l1_ratio=0.5, tol = 1e-6)  # Adjust alpha and l1_ratio as needed\n",
    "elastic_net_model.fit(X_train, y_train)\n",
    "elastic_net_pred = elastic_net_model.predict(X_test)\n",
    "elastic_net_rmse = np.sqrt(mean_squared_error(y_test, elastic_net_pred))\n",
    "elastic_net_r2 = r2_score(y_test, elastic_net_pred)\n",
    "print(f'Elastic Net Regression RMSE: {elastic_net_rmse:.2f}')\n",
    "print(f'Elastic Net Regression R-squared: {elastic_net_r2:.2f}')\n",
    "\n",
    "# Support Vector Regression (SVR)\n",
    "svr_model = SVR(kernel='linear', C=1.0, epsilon=0.2)  # Adjust kernel, C, and epsilon as needed\n",
    "svr_model.fit(X_train, y_train)\n",
    "svr_pred = svr_model.predict(X_test)\n",
    "svr_rmse = np.sqrt(mean_squared_error(y_test, svr_pred))\n",
    "svr_r2 = r2_score(y_test, svr_pred)\n",
    "print(f'SVR RMSE: {svr_rmse:.2f}')\n",
    "print(f'SVR R-squared: {svr_r2:.2f}')\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "gradient_boosting_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=42)  # Adjust parameters as needed\n",
    "gradient_boosting_model.fit(X_train, y_train)\n",
    "gradient_boosting_pred = gradient_boosting_model.predict(X_test)\n",
    "gradient_boosting_rmse = np.sqrt(mean_squared_error(y_test, gradient_boosting_pred))\n",
    "gradient_boosting_r2 = r2_score(y_test, gradient_boosting_pred)\n",
    "print(f'Gradient Boosting RMSE: {gradient_boosting_rmse:.2f}')\n",
    "print(f'Gradient Boosting R-squared: {gradient_boosting_r2:.2f}')\n",
    "\n",
    "# Random Forest Regressor\n",
    "random_forest_model = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42)  # Adjust parameters as needed\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "random_forest_pred = random_forest_model.predict(X_test)\n",
    "random_forest_rmse = np.sqrt(mean_squared_error(y_test, random_forest_pred))\n",
    "random_forest_r2 = r2_score(y_test, random_forest_pred)\n",
    "print(f'Random Forest RMSE: {random_forest_rmse:.2f}')\n",
    "print(f'Random Forest R-squared: {random_forest_r2:.2f}')\n",
    "\n",
    "# K-Nearest Neighbors (KNN) Regression\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)  # Adjust n_neighbors as needed\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "knn_rmse = np.sqrt(mean_squared_error(y_test, knn_pred))\n",
    "knn_r2 = r2_score(y_test, knn_pred)\n",
    "print(f'KNN Regression RMSE: {knn_rmse:.2f}')\n",
    "print(f'KNN Regression R-squared: {knn_r2:.2f}')\n",
    "\n",
    "# Bayesian Linear Regression\n",
    "bayesian_model = BayesianRidge()  # Adjust parameters as needed\n",
    "bayesian_model.fit(X_train, y_train)\n",
    "bayesian_pred = bayesian_model.predict(X_test)\n",
    "bayesian_rmse = np.sqrt(mean_squared_error(y_test, bayesian_pred))\n",
    "bayesian_r2 = r2_score(y_test, bayesian_pred)\n",
    "print(f'Bayesian Linear Regression RMSE: {bayesian_rmse:.2f}')\n",
    "print(f'Bayesian Linear Regression R-squared: {bayesian_r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "65214b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C2</td>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>237000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1</td>\n",
       "      <td>B0</td>\n",
       "      <td>C11</td>\n",
       "      <td>D4</td>\n",
       "      <td>100</td>\n",
       "      <td>E4</td>\n",
       "      <td>F2</td>\n",
       "      <td>86193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C18</td>\n",
       "      <td>D0</td>\n",
       "      <td>0</td>\n",
       "      <td>E0</td>\n",
       "      <td>F2</td>\n",
       "      <td>169200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2</td>\n",
       "      <td>B0</td>\n",
       "      <td>C11</td>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C67</td>\n",
       "      <td>D1</td>\n",
       "      <td>0</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>A1</td>\n",
       "      <td>B0</td>\n",
       "      <td>C2</td>\n",
       "      <td>D1</td>\n",
       "      <td>0</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C8</td>\n",
       "      <td>D1</td>\n",
       "      <td>0</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>129300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C7</td>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>275300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C11</td>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C2</td>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>E1</td>\n",
       "      <td>F2</td>\n",
       "      <td>191475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2628 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     col_0 col_1 col_2 col_3  col_4 col_5 col_6       y\n",
       "0       A0    B0    C2    D1    100    E1    F2  237000\n",
       "1       A1    B0   C11    D4    100    E4    F2   86193\n",
       "2       A0    B0   C18    D0      0    E0    F2  169200\n",
       "3       A2    B0   C11    D1    100    E1    F2   58000\n",
       "4       A0    B0   C67    D1      0    E1    F2  235000\n",
       "...    ...   ...   ...   ...    ...   ...   ...     ...\n",
       "2623    A1    B0    C2    D1      0    E1    F2  102100\n",
       "2624    A0    B0    C8    D1      0    E1    F2  129300\n",
       "2625    A0    B0    C7    D1    100    E1    F2  275300\n",
       "2626    A0    B0   C11    D1    100    E1    F2  150000\n",
       "2627    A0    B0    C2    D1    100    E1    F2  191475\n",
       "\n",
       "[2628 rows x 8 columns]"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "68d2422e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col_0    139\n",
       "col_1     86\n",
       "col_2      0\n",
       "col_3      0\n",
       "col_4      0\n",
       "col_5      0\n",
       "col_6    112\n",
       "y          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "58fdcfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col_0'] = df['col_0'].fillna(df['col_0'].mode(), inplace=True)\n",
    "df['col_1'] = df['col_0'].fillna(df['col_0'].mode(), inplace=True)\n",
    "df['col_6'] = df['col_0'].fillna(df['col_0'].mode(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "4b1e6c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTRAIN, XTEST, YTRAIN, YTEST = train_test_split(df.drop('y', axis=1), df['y'], test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "0501685d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 51166.35\n",
      "Random Forest R-squared: 0.42\n"
     ]
    }
   ],
   "source": [
    "random_forest_model = RandomForestRegressor(n_estimators=1000, max_depth=100, random_state=42)  # Adjust parameters as needed\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "random_forest_pred = random_forest_model.predict(X_test)\n",
    "random_forest_rmse = np.sqrt(mean_squared_error(y_test, random_forest_pred))\n",
    "random_forest_r2 = r2_score(y_test, random_forest_pred)\n",
    "print(f'Random Forest RMSE: {random_forest_rmse:.2f}')\n",
    "print(f'Random Forest R-squared: {random_forest_r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b137a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
